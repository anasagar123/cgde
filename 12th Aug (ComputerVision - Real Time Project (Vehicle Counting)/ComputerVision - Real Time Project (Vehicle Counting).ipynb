{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fc94a9-811c-47d8-9cd8-d5d2cc5e51ea",
   "metadata": {},
   "source": [
    "# ComputerVision - Real Time Project (Vehicle Counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4d4f76-acd2-4a46-9866-01cfe386e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from time import sleep # counting vehicle thats why i import the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24875b5e-f76f-4846-b7bd-b1d40dc267c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling the web camera\n",
    "cap = cv2.VideoCapture('video.mp4') # video camera is enabling\n",
    "# algo = cv2.createBackgroundSubtractorMOG2() # here so many noise is there compare to createBackgroundSubtractorKNN() \n",
    "algo = cv2.createBackgroundSubtractorKNN() # here less noise is there compare to createBackgroundSubtractorMOG2() \n",
    "# createBackgroundSubtractorMOG2 is one of the major Image Processing(like Image detection,image segmentation) task.\n",
    "\n",
    "while True:\n",
    "    ret,frame1 = cap.read()\n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3),5)\n",
    "    # Applaying preprocessing in each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5,5))) # dilate(reduce the noise value) means filling the gap in the detected object\n",
    "                                                # fill 5 by 5 matrix\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)) # kernel will create structure because to use the morphology operation(noise data get removed)\n",
    "    dilatada = cv2.morphologyEx(dilat,cv2.MORPH_CLOSE,kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    counterShape = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow(\"Detector Video\",dilatada)\n",
    "\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1219a69b-1ec0-4a74-8754-fd56abc97f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car is detecting :1\n",
      "Car is detecting :2\n",
      "Car is detecting :3\n",
      "Car is detecting :4\n",
      "Car is detecting :5\n",
      "Car is detecting :6\n",
      "Car is detecting :7\n",
      "Car is detecting :8\n",
      "Car is detecting :9\n",
      "Car is detecting :10\n"
     ]
    }
   ],
   "source": [
    "min_width_rect = 80\n",
    "min_height_rect = 80\n",
    "offset = 6\n",
    "delay = 60\n",
    "carros = 0 # count the number of vehicle detect\n",
    "count_line_pos = 550\n",
    "detec = []\n",
    "\n",
    "def central_handle(x,y,w,h):\n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "    \n",
    "\n",
    "# Enabling the web camera\n",
    "cap = cv2.VideoCapture('video.mp4') # video camera is enabling\n",
    "# algo = cv2.createBackgroundSubtractorMOG2() # here so many noise is there compare to createBackgroundSubtractorKNN() \n",
    "algo = cv2.createBackgroundSubtractorKNN() # here less noise is there compare to createBackgroundSubtractorMOG2() \n",
    "# createBackgroundSubtractorMOG2 is one of the major Image Processing(like Image detection,image segmentation) task.\n",
    "\n",
    "while True:\n",
    "    ret,frame1 = cap.read()\n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3),5)\n",
    "    # Applaying preprocessing in each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5,5))) # dilate(reduce the noise value) means filling the gap in the detected object\n",
    "                                                # fill 5 by 5 matrix\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)) # kernel will create structure because to use the morphology operation(noise data get removed)\n",
    "    dilatada = cv2.morphologyEx(dilat,cv2.MORPH_CLOSE,kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    counterShape, h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.line(frame1, (25,count_line_pos), (1200,count_line_pos), (0,0,255),3) # \n",
    "    # start line = 25,count_line_pos\n",
    "    # end line = 1200,count_line_pos\n",
    "    # line color = (0,0,255)\n",
    "    # thickness of the line = 3\n",
    "\n",
    "    for (i,c) in enumerate(counterShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        validar_contorno = (w>=min_width_rect) and (h>=min_height_rect)\n",
    "        if not validar_contorno:\n",
    "            continue\n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        # original image = frame1\n",
    "        # x axis =  (x,y)\n",
    "        # y - axis = (x+w, y+h)\n",
    "        # color  = (0,255,0)\n",
    "        # thickness = 2\n",
    "        cv2.putText(frame1, \"Vehicle\" + str(carros), (x, y-20), cv2.FONT_HERSHEY_TRIPLEX, 1, (255,0,255),2)\n",
    "        center = central_handle(x,y,w,h)\n",
    "        detec.append(center)\n",
    "        cv2.circle(frame1, center, 4, (200,100,50),-1)\n",
    "\n",
    "\n",
    "        # Loop Function - checking if the vehicle crossed the line\n",
    "        for (x,y) in detec:\n",
    "            if y<(count_line_pos+offset) and y>(count_line_pos-offset):\n",
    "                carros+=1\n",
    "                cv2.line(frame1, (25,count_line_pos), (1200,count_line_pos),(0,0,255), 3)\n",
    "                detec.remove((x,y))\n",
    "                print(\"Car is detecting :\" +str(carros))\n",
    "\n",
    "    cv2.putText(frame1, \"Vehicle\" + str(carros), (x, y-20), cv2.FONT_HERSHEY_TRIPLEX, 1, (255,0,255),2)\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"Original Video\",frame1)\n",
    "\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd73bd-d9ac-40a6-a686-78ad4eafb937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f44a3-7457-4e7d-ace2-a7d2b424824e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b829f792-840c-49cc-8de5-a7586bb3b523",
   "metadata": {},
   "source": [
    "# Tomato_Leaf_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2928c-e73c-4c48-b23f-0b38b1bbc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tomato leaf dataset\n",
    "!unzip '/content/drive/MyDrive/Tomato_Leaf/tomato_leaf_images.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0fcb8-7847-4a4f-a755-b61841481942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "training_data = Path('tomato_leaf_images/train')\n",
    "validation_data = Path('tomato_leaf_images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445130f1-2a5d-4d66-abbb-f505c2e17b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'AmericanLeafMiner':0, 'Healthy':1,'MagnesiumDeficiency':2,\n",
    "               'SerpentineLeafMiner':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0f346-0562-492b-9fad-f98c0287e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "train_df = []\n",
    "for folder in os.listdir(training_data):\n",
    "  imgs_path = training_data / folder\n",
    "  imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "  for img_name in imgs:\n",
    "    train_df.append((str(img_name),labels_dict[folder] ))\n",
    "train_df = pd.DataFrame(train_df, columns = ['image', 'label'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f4e37-6d5b-4822-a357-02599f0b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94637ba1-64ef-4ab3-9a5c-0c4ac3ce4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9033d-d24b-4015-838b-bb1f1b73b436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ae757-a7bc-4e23-9e70-7854cbd928b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
